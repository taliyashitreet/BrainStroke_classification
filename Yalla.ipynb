{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 15:34:53.165248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/taliyas/PycharmProjects/HeartAtact/venv/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n0    Male  67.0             0              1          Yes        Private   \n1    Male  80.0             0              1          Yes        Private   \n2  Female  49.0             0              0          Yes        Private   \n3  Female  79.0             1              0          Yes  Self-employed   \n4    Male  81.0             0              0          Yes        Private   \n\n  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n0          Urban             228.69  36.6  formerly smoked       1  \n1          Rural             105.92  32.5     never smoked       1  \n2          Urban             171.23  34.4           smokes       1  \n3          Rural             174.12  24.0     never smoked       1  \n4          Urban             186.21  29.0  formerly smoked       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>formerly smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>smokes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Self-employed</td>\n      <td>Rural</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>never smoked</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>81.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>186.21</td>\n      <td>29.0</td>\n      <td>formerly smoked</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/taliyas/Downloads/brain_stroke.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:  (4981, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": "gender               0\nage                  0\nhypertension         0\nheart_disease        0\never_married         0\nwork_type            0\nResidence_type       0\navg_glucose_level    0\nbmi                  0\nsmoking_status       0\nstroke               0\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"df shape: \", df.shape)\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map({'Female':1,'Male':0})\n",
    "df['ever_married'] = df['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "df['work_type'] = df['work_type'].map({'Private': 0, 'Self-employed': 1, 'Govt_job':2, 'children':3})\n",
    "df['Residence_type'] = df['Residence_type'].map({'Urban': 1, 'Rural':0})\n",
    "df['smoking_status'] = df['smoking_status'].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   gender   age  hypertension  heart_disease  ever_married  work_type  \\\n0       0  67.0             0              1             1          0   \n1       0  80.0             0              1             1          0   \n2       1  49.0             0              0             1          0   \n3       1  79.0             1              0             1          1   \n4       0  81.0             0              0             1          0   \n5       0  74.0             1              1             1          0   \n6       1  69.0             0              0             0          0   \n7       1  78.0             0              0             1          0   \n8       1  81.0             1              0             1          0   \n9       1  61.0             0              1             1          2   \n\n   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n0               1             228.69  36.6               0       1  \n1               0             105.92  32.5               1       1  \n2               1             171.23  34.4               2       1  \n3               0             174.12  24.0               1       1  \n4               1             186.21  29.0               0       1  \n5               0              70.09  27.4               1       1  \n6               1              94.39  22.8               1       1  \n7               1              58.57  24.2               3       1  \n8               0              80.43  29.7               1       1  \n9               0             120.46  36.8               2       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>228.69</td>\n      <td>36.6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>105.92</td>\n      <td>32.5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>171.23</td>\n      <td>34.4</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>79.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>174.12</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>81.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>186.21</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>74.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>70.09</td>\n      <td>27.4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>69.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>94.39</td>\n      <td>22.8</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>78.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58.57</td>\n      <td>24.2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>81.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80.43</td>\n      <td>29.7</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>61.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>120.46</td>\n      <td>36.8</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(22)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3736, 11)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = df.sample(frac=0.75, random_state=1)\n",
    "train_dataset.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(1245, 11)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = df.drop(train_dataset.index)\n",
    "test_dataset.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "x_train, y_train = train_dataset.iloc[:,:-1], train_dataset.iloc[:,-1:]\n",
    "x_test, y_test = test_dataset.iloc[:,:-1], test_dataset.iloc[:,-1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 15:37:30.777845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = tf.convert_to_tensor(x_train, dtype=tf.float32), tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "x_test, y_test = tf.convert_to_tensor(x_test, dtype=tf.float32), tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class Normalize(tf.Module):\n",
    "  def __init__(self, x):\n",
    "    # Initialize the mean and standard deviation for normalization\n",
    "    self.mean = tf.Variable(tf.math.reduce_mean(x, axis=0))\n",
    "    self.std = tf.Variable(tf.math.reduce_std(x, axis=0))\n",
    "\n",
    "  def norm(self, x):\n",
    "    # Normalize the input\n",
    "    return (x - self.mean)/self.std\n",
    "\n",
    "  def unnorm(self, x):\n",
    "    # Unnormalize the input\n",
    "    return (x * self.std) + self.mean\n",
    "\n",
    "norm_x = Normalize(x_train)\n",
    "x_train_norm, x_test_norm = norm_x.norm(x_train), norm_x.norm(x_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def log_loss(y_pred, y):\n",
    "  # Compute the log loss function\n",
    "  ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_pred)\n",
    "  return tf.reduce_mean(ce)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class LogisticRegression(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.built = False\n",
    "\n",
    "  def __call__(self, x, train=True):\n",
    "    # Initialize the model parameters on the first call\n",
    "    if not self.built:\n",
    "      # Randomly generate the weights and the bias term\n",
    "      rand_w = tf.random.uniform(shape=[x.shape[-1], 1], seed=22)\n",
    "      rand_b = tf.random.uniform(shape=[], seed=22)\n",
    "      self.w = tf.Variable(rand_w)\n",
    "      self.b = tf.Variable(rand_b)\n",
    "      self.built = True\n",
    "    # Compute the model output\n",
    "    z = tf.add(tf.matmul(x, self.w), self.b)\n",
    "    z = tf.squeeze(z, axis=1)\n",
    "    if train:\n",
    "      return z\n",
    "    return tf.sigmoid(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "log_reg = LogisticRegression()\n",
    "y_pred = log_reg(x_train_norm[:5], train=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def predict_class(y_pred, thresh=0.5):\n",
    "  # Return a tensor with  `1` if `y_pred` > `0.5`, and `0` otherwise\n",
    "  return tf.cast(y_pred > thresh, tf.float32)\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "  # Return the proportion of matches between `y_pred` and `y`\n",
    "  y_pred = tf.math.sigmoid(y_pred)\n",
    "  y_pred_class = predict_class(y_pred)\n",
    "  check_equal = tf.cast(y_pred_class == y,tf.float32)\n",
    "  acc_val = tf.reduce_mean(check_equal)\n",
    "  return acc_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# tf.compat.v1.enable_eager_execution()\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=x_train.shape[0]).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`logits` and `labels` must have the same shape, received ((64,) vs (64, 1)).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[1;32m     15\u001B[0m   y_pred_batch \u001B[38;5;241m=\u001B[39m log_reg(x_batch)\n\u001B[0;32m---> 16\u001B[0m   batch_loss \u001B[38;5;241m=\u001B[39m \u001B[43mlog_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m batch_acc \u001B[38;5;241m=\u001B[39m accuracy(y_pred_batch, y_batch)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Update the parameters with respect to the gradient calculations\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m, in \u001B[0;36mlog_loss\u001B[0;34m(y_pred, y)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_loss\u001B[39m(y_pred, y):\n\u001B[1;32m      2\u001B[0m   \u001B[38;5;66;03m# Compute the log loss function\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m   ce \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid_cross_entropy_with_logits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mreduce_mean(ce)\n",
      "File \u001B[0;32m~/PycharmProjects/HeartAtact/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/HeartAtact/venv/lib/python3.9/site-packages/tensorflow/python/ops/nn_impl.py:129\u001B[0m, in \u001B[0;36msigmoid_cross_entropy_with_logits\u001B[0;34m(_sentinel, labels, logits, name)\u001B[0m\n\u001B[1;32m    127\u001B[0m   labels\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;241m.\u001B[39massert_is_compatible_with(logits\u001B[38;5;241m.\u001B[39mget_shape())\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`logits` and `labels` must have the same shape, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    130\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceived (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlogits\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m vs \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    131\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# The logistic loss formula from above is\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;66;03m#   x - x * z + log(1 + exp(-x))\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;66;03m# For x < 0, a more numerically stable formula is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# To allow computing gradients at zero, we define custom versions of max and\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;66;03m# abs functions.\u001B[39;00m\n\u001B[1;32m    141\u001B[0m zeros \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mzeros_like(logits, dtype\u001B[38;5;241m=\u001B[39mlogits\u001B[38;5;241m.\u001B[39mdtype)\n",
      "\u001B[0;31mValueError\u001B[0m: `logits` and `labels` must have the same shape, received ((64,) vs (64, 1))."
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "train_losses, test_losses = [], []\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "# Set up the training loop and begin training\n",
    "for epoch in range(epochs):\n",
    "  batch_losses_train, batch_accs_train = [], []\n",
    "  batch_losses_test, batch_accs_test = [], []\n",
    "\n",
    "  # Iterate over the training data\n",
    "  for  x_batch, y_batch in train_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred_batch = log_reg(x_batch)\n",
    "      batch_loss = log_loss(y_pred_batch, y_batch)\n",
    "    batch_acc = accuracy(y_pred_batch, y_batch)\n",
    "    # Update the parameters with respect to the gradient calculations\n",
    "    grads = tape.gradient(batch_loss, log_reg.variables)\n",
    "    for g,v in zip(grads, log_reg.variables):\n",
    "      v.assign_sub(learning_rate * g)\n",
    "    # Keep track of batch-level training performance\n",
    "    batch_losses_train.append(batch_loss)\n",
    "    batch_accs_train.append(batch_acc)\n",
    "\n",
    "  # Iterate over the testing data\n",
    "  for x_batch, y_batch in test_dataset:\n",
    "    y_pred_batch = log_reg(x_batch)\n",
    "    batch_loss = log_loss(y_pred_batch, y_batch)\n",
    "    batch_acc = accuracy(y_pred_batch, y_batch)\n",
    "    # Keep track of batch-level testing performance\n",
    "    batch_losses_test.append(batch_loss)\n",
    "    batch_accs_test.append(batch_acc)\n",
    "\n",
    "  # Keep track of epoch-level model performance\n",
    "  train_loss, train_acc = tf.reduce_mean(batch_losses_train), tf.reduce_mean(batch_accs_train)\n",
    "  test_loss, test_acc = tf.reduce_mean(batch_losses_test), tf.reduce_mean(batch_accs_test)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accs.append(train_acc)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accs.append(test_acc)\n",
    "  if epoch % 20 == 0:\n",
    "    print(f\"Epoch: {epoch}, Training log loss: {train_loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}